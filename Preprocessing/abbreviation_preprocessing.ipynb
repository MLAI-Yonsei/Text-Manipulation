{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"QbBKRRDLrugj"},"outputs":[],"source":["import os\n","import json\n","import re\n","from difflib import SequenceMatcher\n","from Levenshtein import ratio  # Levenshtein Distance\n","from jamo import h2j  # Converts Hangul characters into Jamo units"]},{"cell_type":"markdown","metadata":{"id":"CEgcvWwbrugl"},"source":["## Determine Language & Define File Paths"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"vRvVwP14rugn"},"outputs":[],"source":["# Determine Language Based on File Name\n","DATA_ORIGINAL = \"eng_abbreviations.json\"\n","filename = os.path.basename(DATA_ORIGINAL)\n","IS_KOREAN = filename.startswith(\"kor_\")\n","IS_ENGLISH = not IS_KOREAN\n","\n","# List of files to process\n","file_paths = [\n","    \" \",\n","    \" \",\n","    \" \"\n","]"]},{"cell_type":"markdown","metadata":{"id":"_Y7131-Brugn"},"source":["## Load Reference Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"1Pd2SbTurugo"},"outputs":[],"source":["# Load the reference dataset\n","with open(DATA_ORIGINAL, \"r\", encoding=\"utf-8\") as file:\n","    abbreviation_data = json.load(file)\n","\n","# Convert reference dataset into a dictionary (abbreviation â†’ original phrase)\n","abbreviation_dict = {item[\"transformed\"]: item[\"original\"] for item in abbreviation_data}"]},{"cell_type":"markdown","metadata":{"id":"M3BFBy18wCGs"},"source":["## Preprocess Text Data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"foMSbooIvxVm"},"outputs":[],"source":["# Text cleaning function\n","def clean_text(text: str, keep_pipe=False) -> str:\n","    \"\"\"\n","    Cleans input text based on the preprocessing requirements of the specific task.\n","\n","    Args:\n","        text (str): The input string to be cleaned.\n","        keep_pipe (bool): If True, retains the '|' character (used for original answers with multiple references).\n","\n","    Returns:\n","        str: The cleaned text, processed according to the specified task requirements.\n","    \"\"\"\n","    if isinstance(text, str):\n","        # Remove specific special characters [,],\",\\,?,&,*\n","        text = re.sub(r'[\\[\\]\\\",\\\\\\?\\&\\*]', '', text)\n","\n","        if IS_ENGLISH:\n","            text = text.lower()  # Convert to lowercase for English processing\n","\n","        if keep_pipe:\n","            pass  # Keep '|' character if necessary\n","        else:\n","            text = text.replace(\"|\", \"\")  # Remove '|' if not needed\n","\n","        # Remove spaces\n","        text = text.replace(\" \", \"\")\n","\n","    return text"]},{"cell_type":"markdown","metadata":{"id":"WnepMhKbrugo"},"source":["## Define Similarity Metrics"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"czipDOYQrugp"},"outputs":[],"source":["# Similarity measurement functions\n","def sequence_similarity(a, b):\n","    \"\"\"Computes SequenceMatcher similarity score between two strings.\"\"\"\n","    return SequenceMatcher(None, a, b).ratio()\n","\n","def levenshtein_similarity(a, b):\n","    \"\"\"Computes Levenshtein similarity score between two strings.\"\"\"\n","    return ratio(a, b)\n","\n","# Function to extract Jamo (Korean phonetic units)\n","def get_jamo(word):\n","    \"\"\"Extracts Jamo representation from Korean text using h2j().\"\"\"\n","    return h2j(word)  # Converts Hangul to Jamo\n","\n","# Jamo-based similarity function (applied only to Korean data)\n","def jamo_similarity(word1, word2):\n","    \"\"\"Computes similarity based on Jamo decomposition for Korean text.\"\"\"\n","    jamo1 = get_jamo(word1)\n","    jamo2 = get_jamo(word2)\n","\n","    common_count = sum(1 for a, b in zip(jamo1, jamo2) if a == b)\n","    max_length = max(len(jamo1), len(jamo2))\n","\n","    return common_count / max_length if max_length > 0 else 0"]},{"cell_type":"markdown","metadata":{"id":"FBZhsXxlrugp"},"source":["## Answer Selection & Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMW0I35Grugq"},"outputs":[],"source":["# Function to split answers while preserving commas inside quotes\n","def smart_split(answer_text):\n","    \"\"\"Splits a string while preserving content inside single quotes.\"\"\"\n","    matches = re.findall(r\"'(.*?)'\", answer_text)  # Extract content inside quotes\n","    return matches if matches else [answer_text.strip(\"'\")]\n","\n","# Function to find the best match when multiple correct answers are possible\n","def get_best_match(answer_list, original_list, is_korean):\n","    \"\"\"Finds the best matching answer from the list of correct answers.\"\"\"\n","    best_match = None\n","    best_score = -1\n","\n","    for ans in answer_list:\n","        for original in original_list:\n","            if is_korean:\n","                score = (sequence_similarity(original, ans) +\n","                         levenshtein_similarity(original, ans) +\n","                         jamo_similarity(original, ans))\n","            else:\n","                score = (sequence_similarity(original, ans) +\n","                         levenshtein_similarity(original, ans))\n","\n","            if score > best_score:\n","                best_match = ans\n","                best_score = score\n","\n","    return best_match\n","\n","# Process each file individually\n","for file_path in file_paths:\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        data = json.load(file)\n","\n","    removed_count = 0  # Counter for removed incorrect answers\n","    selection_log = []  # Log of selected and removed answers\n","\n","    for entry in data:\n","        word = entry.get(\"word\")\n","        original = abbreviation_dict.get(word, None)\n","\n","        if original and \"Answer\" in entry:\n","            # Clean and preprocess the original text\n","            original_cleaned = clean_text(original, keep_pipe=True)\n","            original_list = original_cleaned.split(\"|\") if \"|\" in original_cleaned else [original_cleaned]\n","\n","            # Clean and preprocess the answer text\n","            answer_list = smart_split(entry[\"Answer\"])\n","            answer_list = [clean_text(ans) for ans in answer_list]  # Apply cleaning\n","\n","            if len(answer_list) > 1:\n","                best_match = get_best_match(answer_list, original_list, IS_KOREAN)\n","\n","                # Log removed answers for verification\n","                removed_answers = [ans for ans in answer_list if ans != best_match]\n","                selection_log.append(f\"Word: {word} | Original: {original_cleaned} | Selected: {best_match} | Removed: {removed_answers}\")\n","\n","                # Update the Answer field with the best match\n","                entry[\"Answer\"] = best_match\n","                removed_count += len(removed_answers)  # Update removal count\n","\n","    # Save the modified data back to the original file\n","    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n","        json.dump(data, file, ensure_ascii=False, indent=4)\n","\n","    # Display processing results\n","    print(f\"Processed {file_path}: Removed {removed_count} incorrect answers\")\n","    print(\"\\n\".join(selection_log))  # Log of removed and selected answers"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"ds_study","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
