{"cells":[{"cell_type":"code","source":["import random\n","import pandas as pd\n","import json"],"metadata":{"id":"MEf5p6EUc7Mp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qlHE9CmjNjlf"},"outputs":[],"source":["# Read toeic data\n","df1 = pd.read_excel(\" \")\n","\n","# 'words' column to list\n","df1 = df1.dropna(subset=['words']).reset_index(drop=True)\n","words1 = df1['words'].tolist()\n","\n","# seperate letters to \" , \"\n","split_words_toeic = [\", \".join(list(word.lower())) for word in words1]\n","\n","# Append new column\n","df1['Split_Letters'] = split_words_toeic\n","\n","# List up the toefl noun words (same process)\n","\n","df2 = pd.read_excel(\" \")\n","\n","words2 = df2['words'].dropna().tolist()\n","\n","split_words_toefl = [\", \".join(list(word.lower())) for word in words2]\n","\n","df2['Split_Letters'] = split_words_toefl\n","\n","print(df1.info)\n","print(df2.info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8yGTq_tNjlh"},"outputs":[],"source":["# Concatenate df1 and df2 vertically (row-wise)\n","df = pd.concat([df1, df2])\n","\n","# Remove duplicate rows, keeping only the first occurrence\n","# The ignore_index=True option resets the index after dropping duplicates\n","df.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n","\n","\n","print(df.info())\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nuBU9ENHNjli"},"outputs":[],"source":["# Add \" ' \" and \" , \"\n","def add_quotes_to_letters(split_words):\n","    \"\"\"\n","    Format a comma-separated string of letters by adding single quotes around each letter\n","    and ensuring proper spacing.\n","\n","    Args:\n","        split_words (str): A string of letters separated by commas.\n","\n","    Returns:\n","        str: A formatted string representing a list with each letter enclosed in single quotes.\n","\n","    Example:\n","        Input: \"a, b, c\"\n","        Output: \"['a', 'b', 'c']\"\n","    \"\"\"\n","    letters = [f\"'{letter.strip()}'\" for letter in split_words.split(\",\")]\n","    return \"[\" + \", \".join(letters) + \"]\"\n","\n","# Randomized Letters\n","def shuffle_letters(quoted_letters):\n","    \"\"\"\n","    Shuffle the order of letters in a formatted list.\n","\n","    Args:\n","        quoted_letters (str): A string representation of a list of letters.\n","\n","    Returns:\n","        str: A string representation of the shuffled list of letters.\n","\n","    Example:\n","        Input: \"['a', 'b', 'c']\"\n","        Output: \"['b', 'c', 'a']\" (order may vary)\n","    \"\"\"\n","    letters_list = eval(quoted_letters)  # Convert string list to actual list\n","    random.shuffle(letters_list)  # Shuffle the letters in the list\n","    return str(letters_list)\n","\n","# Append New column\n","df['list'] = df['Split_Letters'].apply(add_quotes_to_letters)\n","df['random'] = df['list'].apply(shuffle_letters)\n","\n","df.drop(columns='list', inplace=True)\n","\n","\n","# Save\n","df.to_excel(\" \", index=False)\n","\n","print(df.info())\n","df.head()"]},{"cell_type":"code","source":["# Load the Excel file\n","file_path = \" \"\n","df = pd.read_excel(file_path)\n","\n","# Select only the required columns (words, random)\n","df = df[['words', 'random']]\n","\n","# Convert to JSON format\n","data = df.to_dict(orient=\"records\")\n","\n","# Save as a JSON file\n","json_path = \" \"\n","with open(json_path, \"w\", encoding=\"utf-8\") as f:\n","    json.dump(data, f, ensure_ascii=False, indent=3)\n","\n","print(\"JSON save:\", json_path)"],"metadata":{"id":"jf__EsTMjRDK"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}