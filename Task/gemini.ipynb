{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from dotenv import load_dotenv \n",
    "\n",
    "import google.generativeai as genai "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Load dataset from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the dataset JSON file.\n",
    "\n",
    "    Returns:\n",
    "        list: Loaded dataset as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# File path for dataset\n",
    "DATA_FILE = \" \"  \n",
    "\n",
    "# Load dataset\n",
    "data = load_data(DATA_FILE)\n",
    "print(f\"Dataset Loaded: {len(data)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load API Key & Initialize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "print(\"API Key Loaded and Gemini Client Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompts(file_path: str, category: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load prompts for a specific category from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the prompts JSON file.\n",
    "        category (str): The category key (e.g., 'eng_abbreviations', 'kor_abbreviations').\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing different prompt templates.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        prompt_data = json.load(file)\n",
    "\n",
    "    return prompt_data.get(category, {})\n",
    "\n",
    "# File path and category for prompts\n",
    "PROMPT_FILE = \" \"  \n",
    "CATEGORY = \" \"  \n",
    "\n",
    "# Load prompts\n",
    "prompts = load_prompts(PROMPT_FILE, CATEGORY)\n",
    "print(f\"Loaded prompts for category '{CATEGORY}': {list(prompts.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Requests to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini_api(prompt_text: str, input_word: str) -> str:\n",
    "    \"\"\"\n",
    "    Call the Gemini API with a specific prompt and input word.\n",
    "\n",
    "    Args:\n",
    "        prompt_text (str): The system prompt to use.\n",
    "        input_word (str): The input word to process.\n",
    "\n",
    "    Returns:\n",
    "        str: The API response text.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-flash\",\n",
    "        system_instruction=prompt_text\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(f\"{input_word}\")\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_word}: {e}\")\n",
    "        return \"Error\"\n",
    "\n",
    "print(\"Gemini API Function Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Answer from Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(response_text: str, category: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the answer from response text based on the category prefix.\n",
    "\n",
    "    Args:\n",
    "        response_text (str): Full response text from Gemini API.\n",
    "        category (str): Prompt category (e.g., \"eng_abbreviations\" or \"kor_abbreviations\").\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted answer or full response if no match is found.\n",
    "    \"\"\"\n",
    "    if category.startswith(\"eng_\"):\n",
    "        match = re.search(r\"Answer:\\s*(.*)\", response_text)\n",
    "    else:\n",
    "        match = re.search(r\"답변:\\s*(.*)\", response_text)\n",
    "\n",
    "    return match.group(1).strip() if match else response_text  # Extracted answer or full response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results: list, filename: str):\n",
    "    \"\"\"\n",
    "    Save processed results into a JSON file.\n",
    "\n",
    "    Args:\n",
    "        results (list): List of dictionaries containing \"word\", \"response\", and \"answer\".\n",
    "        filename (str): Path to the output JSON file.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(results, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Results saved: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute API Calls and Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save results\n",
    "RESULTS_DIR = \"results\"\n",
    "CHECKPOINT_DIR = \"checkpoint\" \n",
    "\n",
    "# Ensure checkpoint directory exists\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "for prompt_type, prompt_text in prompts.items():\n",
    "    results = []\n",
    "    progress_file = os.path.join(CHECKPOINT_DIR, f\"{prompt_type}_progress.txt\")\n",
    "\n",
    "    # Load progress checkpoint or create if missing\n",
    "    if os.path.exists(progress_file):\n",
    "        with open(progress_file, \"r\") as f:\n",
    "            start_index = int(f.read().strip() or \"0\")  # Default to 0 if file is empty\n",
    "    else:\n",
    "        start_index = 0\n",
    "        with open(progress_file, \"w\") as f:\n",
    "            f.write(\"0\")  # Create file with initial index 0\n",
    "\n",
    "    print(f\"Processing {prompt_type} (Starting from index {start_index})...\")\n",
    "\n",
    "    for idx in range(start_index, len(data)):  \n",
    "        input_word = data[idx][\"transformed\"]  \n",
    "        response_text = call_gemini_api(prompt_text, input_word)\n",
    "\n",
    "        # Extract answer based on category (eng_ → \"Answer:\", kor_ → \"답변:\")\n",
    "        extracted_answer = extract_answer(response_text, CATEGORY)\n",
    "\n",
    "        results.append({\n",
    "            \"word\": input_word,     # Store original transformed word\n",
    "            \"response\": response_text,  # Store full response\n",
    "            \"answer\": extracted_answer  # Store extracted answer\n",
    "        })\n",
    "\n",
    "        # Save progress checkpoint\n",
    "        with open(progress_file, \"w\") as f:\n",
    "            f.write(str(idx + 1))\n",
    "\n",
    "        # Pause every 15 requests\n",
    "        if (idx + 1) % 15 == 0 and (idx + 1) < len(data):\n",
    "            print(\"Sleeping for 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    # Save results\n",
    "    output_filename = os.path.join(RESULTS_DIR, f\"{prompt_type}_results.json\")\n",
    "    save_results(results, output_filename)\n",
    "\n",
    "print(\"All Processing Completed Successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
