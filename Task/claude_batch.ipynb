{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"47xbzzobvzdA"},"outputs":[],"source":["import os\n","import json\n","import re\n","import requests\n","from dotenv import load_dotenv\n","\n","import anthropic\n","from anthropic.types.message_create_params import MessageCreateParamsNonStreaming\n","from anthropic.types.messages.batch_create_params import Request"]},{"cell_type":"markdown","metadata":{"id":"4pXkh8QcvzdD"},"source":["## Load Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXXUVAO3vzdE"},"outputs":[],"source":["def load_data(file_path: str) -> list:\n","    \"\"\"\n","    Load dataset from a JSON file.\n","\n","    Args:\n","        file_path (str): Path to the dataset JSON file.\n","\n","    Returns:\n","        list: Loaded dataset as a list of dictionaries.\n","    \"\"\"\n","    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","        return json.load(f)[:5]\n","\n","# File paths\n","DATA_FILE = \" \"\n","\n","# Load dataset\n","data = load_data(DATA_FILE)\n","print(f\"Dataset Loaded: {len(data)} samples.\")"]},{"cell_type":"markdown","metadata":{"id":"OUFIuo6ovzdE"},"source":["## Load API Key & Initialize Client"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXvKIkstvzdF"},"outputs":[],"source":["load_dotenv()\n","api_key = os.getenv(\"CLAUDE_API_KEY\")\n","client = anthropic.Anthropic(api_key=api_key)\n","\n","print(\"API Key Loaded and Client Initialized.\")"]},{"cell_type":"markdown","metadata":{"id":"4VjNoqPXvzdF"},"source":["## Load Prompts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2j4x_25vzdF"},"outputs":[],"source":["def load_prompt_set(file_path: str, category: str) -> dict:\n","    \"\"\"\n","    Load prompts for a specific category from a JSON file.\n","\n","    Args:\n","        file_path (str): Path to the prompts JSON file.\n","        category (str): The category key (e.g., 'eng_abbreviations', 'kor_abbreviations').\n","\n","    Returns:\n","        dict: Dictionary containing different prompt templates.\n","    \"\"\"\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        prompt_data = json.load(file)\n","\n","    return prompt_data.get(category, {})\n","\n","# File path and category for prompts\n","PROMPT_FILE = \" \"\n","CATEGORY = \" \"\n","\n","# Load prompts\n","prompts = load_prompt_set(PROMPT_FILE, CATEGORY)\n","print(f\"Loaded prompts for category '{CATEGORY}': {list(prompts.keys())}\")"]},{"cell_type":"markdown","metadata":{"id":"pRhAo8jQvzdG"},"source":["## Send Requests to API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QFvbrltKvzdG"},"outputs":[],"source":["batch_ids = {}\n","for prompt_type in [\"zrs_prompt\", \"cot_prompt\", \"icl_prompt\"]:\n","    batch_requests = [\n","        Request(\n","            custom_id=f\"{prompt_type}-request-{idx + 1}\",\n","            params=MessageCreateParamsNonStreaming(\n","                model=\"claude-3-5-sonnet-20241022\",\n","                max_tokens=1024,\n","                system=[{\"type\": \"text\", \"text\": prompts[prompt_type]}],\n","                messages=[{\"role\": \"user\", \"content\": item[\"transformed\"]}]\n","            )\n","        )\n","        for idx, item in enumerate(data)\n","    ]\n","\n","    batch_response = client.messages.batches.create(requests=batch_requests)\n","    batch_ids[prompt_type] = batch_response.id\n","print(\"Batch Requests Sent.\")"]},{"cell_type":"markdown","metadata":{"id":"DnlJqG4MvzdH"},"source":["## Check API Request Status"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZL6KgmuvzdH"},"outputs":[],"source":["def check_batch_status(client, batch_id: str) -> str:\n","    \"\"\"\n","    Checks the processing status of a batch request.\n","\n","    Args:\n","        client: Anthropic API client instance.\n","        batch_id (str): Batch request ID.\n","\n","    Returns:\n","        str: Status of the batch request (e.g., \"completed\", \"in_progress\", \"failed\").\n","    \"\"\"\n","    batch_status = client.messages.batches.retrieve(batch_id)\n","    return batch_status.processing_status if hasattr(batch_status, \"processing_status\") else \"Unknown\"\n","\n","for prompt_type, batch_id in batch_ids.items():\n","    status = check_batch_status(client, batch_id)\n","    print(f\"Batch {batch_id} Status: {status}\")"]},{"cell_type":"markdown","metadata":{"id":"7TNV49OBvzdH"},"source":["## Retrieve Batch Results & Save to JSON"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3oAzZdPvzdH"},"outputs":[],"source":["# Extracting Answer from Response\n","def extract_answer(response_text: str, category: str) -> str:\n","    \"\"\"\n","    Extracts the answer from the response text based on the category prefix.\n","\n","    Args:\n","        response_text (str): Full response text from Claude API.\n","        category (str): Prompt category (e.g., \"eng_abbreviations\" or \"kor_abbreviations\").\n","\n","    Returns:\n","        str: Extracted answer or full response if no match is found.\n","    \"\"\"\n","    if category.startswith(\"eng_\"):\n","        match = re.search(r\"Answer:\\s*(.*)\", response_text)\n","    else:\n","        match = re.search(r\"답변:\\s*(.*)\", response_text)\n","\n","    return match.group(1).strip() if match else response_text  # Extracted answer or full response\n","\n","# Fetch Batch Results from API\n","def fetch_batch_results(client, batch_id: str, api_key: str) -> list:\n","    \"\"\"\n","    Retrieves batch results from the Claude API.\n","\n","    Args:\n","        client: Anthropic API client.\n","        batch_id (str): Batch request ID.\n","        api_key (str): API authentication key.\n","\n","    Returns:\n","        list: Parsed JSON responses or None if failed.\n","    \"\"\"\n","    batch_result = client.messages.batches.retrieve(batch_id)\n","    if not hasattr(batch_result, \"results_url\"):\n","        return None\n","\n","    response = requests.get(batch_result.results_url, headers={\n","        \"x-api-key\": api_key,\n","        \"Content-Type\": \"application/json\",\n","        \"anthropic-version\": \"2023-06-01\"\n","    })\n","\n","    return [json.loads(line) for line in response.text.splitlines()] if response.status_code == 200 else None\n","\n","# Mapping Custom ID to Original Input\n","def map_custom_id_to_input(data: list) -> dict:\n","    \"\"\"\n","    Creates a mapping from custom_id to the original transformed input word.\n","\n","    Args:\n","        data (list): List of input data containing \"transformed\" words.\n","\n","    Returns:\n","        dict: Mapping from custom_id to transformed input word.\n","    \"\"\"\n","    return {f\"request-{idx + 1}\": item[\"transformed\"] for idx, item in enumerate(data)}\n","\n","id_to_input_map = map_custom_id_to_input(data)\n","\n","# Processing and Saving Results\n","def save_results_to_json(results: list, filename: str) -> None:\n","    \"\"\"\n","    Saves processed results into a JSON file.\n","\n","    Args:\n","        results (list): List of dictionaries containing \"word\", \"response\", and \"answer\".\n","        filename (str): Path to the output JSON file.\n","    \"\"\"\n","    os.makedirs(os.path.dirname(filename), exist_ok=True)  # Ensure results folder exists\n","\n","    with open(filename, \"w\", encoding=\"utf-8\") as file:\n","        json.dump(results, file, ensure_ascii=False, indent=4)\n","\n","    print(f\"Results saved: {filename}\")\n","\n","# Fetch, Process, and Store Results\n","RESULTS_DIR = \"results\"\n","\n","for prompt_type, batch_id in batch_ids.items():\n","    results = fetch_batch_results(client, batch_id, api_key)\n","\n","    if results:\n","        formatted_results = []\n","        for item in results:\n","            custom_id = item[\"custom_id\"]\n","            response_text = item[\"result\"][\"message\"][\"content\"][0][\"text\"]\n","\n","            # Retrieve original word from input map\n","            input_text = id_to_input_map.get(custom_id.replace(f\"{prompt_type}-\", \"\"), \"Unknown\")\n","\n","            # Extract answer using appropriate format\n","            extracted_answer = extract_answer(response_text, CATEGORY)\n","\n","            formatted_results.append({\n","                \"word\": input_text,         # Store original transformed word\n","                \"response\": response_text,  # Store full response\n","                \"answer\": extracted_answer  # Store extracted answer\n","            })\n","\n","        # Save results to JSON file in \"results/\" directory\n","        output_file = os.path.join(RESULTS_DIR, f\"{prompt_type}_results.json\")\n","        save_results_to_json(formatted_results, output_file)\n","\n","print(\"Batch Processing Completed Successfully!\")"]}],"metadata":{"kernelspec":{"display_name":"ds_study","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}