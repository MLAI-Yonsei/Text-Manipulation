{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Load dataset from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the dataset JSON file.\n",
    "\n",
    "    Returns:\n",
    "        list: Loaded dataset as a list of dictionaries.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# File path\n",
    "DATA_FILE = \" \"\n",
    "\n",
    "# Load dataset\n",
    "data = load_data(DATA_FILE)\n",
    "print(f\"Dataset Loaded: {len(data)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load API Key & Initialize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "print(\"API Key Loaded and Client Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompts(file_path: str, category: str) -> dict:\n",
    "    \"\"\"\n",
    "    Load prompts for a specific category from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the prompts JSON file.\n",
    "        category (str): The category key (e.g., 'eng_abbreviations', 'kor_abbreviations').\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing different prompt templates.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        prompt_data = json.load(file)\n",
    "\n",
    "    return prompt_data.get(category, {})\n",
    "\n",
    "# File path and category for prompts\n",
    "PROMPT_FILE = \" \"  \n",
    "CATEGORY = \" \"  \n",
    "\n",
    "# Load prompts\n",
    "prompts = load_prompts(PROMPT_FILE, CATEGORY)\n",
    "print(f\"Loaded prompts for category '{CATEGORY}': {list(prompts.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate JSONL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jsonl_files(data: list, prompts: dict, output_dir: str):\n",
    "    \"\"\"\n",
    "    Generate JSONL files for different prompt types.\n",
    "\n",
    "    Args:\n",
    "        data (list): Dataset to be used for requests.\n",
    "        prompts (dict): Dictionary containing prompts for each type.\n",
    "        output_dir (str): Directory to save JSONL files.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for prompt_type, prompt_text in prompts.items():\n",
    "        jsonl_path = os.path.join(output_dir, f\"{prompt_type}.jsonl\")\n",
    "\n",
    "        with open(jsonl_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "            system_message = {\"role\": \"system\", \"content\": prompt_text}\n",
    "\n",
    "            for idx, item in enumerate(data):\n",
    "                request_data = {\n",
    "                    \"custom_id\": f\"{prompt_type}-request-{idx + 1}\",\n",
    "                    \"method\": \"POST\",\n",
    "                    \"url\": \"/v1/chat/completions\",\n",
    "                    \"body\": {\n",
    "                        \"model\": \"gpt-4o\",\n",
    "                        \"messages\": [\n",
    "                            system_message,\n",
    "                            {\"role\": \"user\", \"content\": item[\"transformed\"]}\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "                outfile.write(json.dumps(request_data, ensure_ascii=False) + \"\\n\")\n",
    "        print(f\"JSONL file created: {jsonl_path}\")\n",
    "\n",
    "# File paths\n",
    "OUTPUT_DIR = \"jsonl\"\n",
    "\n",
    "# Generate JSONL files\n",
    "generate_jsonl_files(data, prompts, OUTPUT_DIR)\n",
    "print(\"JSONL Files Generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Requests to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_batch_requests(client, jsonl_files: list):\n",
    "    \"\"\"\n",
    "    Send batch requests for multiple JSONL files.\n",
    "\n",
    "    Args:\n",
    "        client: OpenAI API client.\n",
    "        jsonl_files (list): List of JSONL file paths.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of batch IDs to prompt types.\n",
    "    \"\"\"\n",
    "    batch_ids = {}\n",
    "\n",
    "    for jsonl_file in jsonl_files:\n",
    "        batch_input_file = client.files.create(\n",
    "            file=open(jsonl_file, \"rb\"),\n",
    "            purpose=\"batch\"\n",
    "        )\n",
    "\n",
    "        batch_input_file_id = batch_input_file.id\n",
    "\n",
    "        batch_response = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\"description\": f\"Batch request for {os.path.basename(jsonl_file)}\"}\n",
    "        )\n",
    "\n",
    "        batch_ids[jsonl_file] = batch_response.id\n",
    "        print(f\"Batch request sent for {jsonl_file}. Batch ID: {batch_response.id}\")\n",
    "\n",
    "    return batch_ids\n",
    "\n",
    "# Get JSONL file paths\n",
    "jsonl_files = [os.path.join(OUTPUT_DIR, f\"{category}.jsonl\") for category in prompts.keys()]\n",
    "\n",
    "# Send batch requests\n",
    "batch_ids = send_batch_requests(client, jsonl_files)\n",
    "print(f\"Batch Requests Sent: {batch_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Batch Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch_results(client, batch_ids: dict):\n",
    "    \"\"\"\n",
    "    Retrieve batch results from OpenAI API using output_file_id.\n",
    "\n",
    "    Args:\n",
    "        client: OpenAI API client.\n",
    "        batch_ids (dict): Mapping of JSONL filenames to batch IDs.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of JSONL filenames to response data.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for jsonl_file, batch_id in batch_ids.items():\n",
    "        batch_info = client.batches.retrieve(batch_id)\n",
    "        status = batch_info.status\n",
    "        output_file_id = batch_info.output_file_id  \n",
    "\n",
    "        print(f\"Checking batch status for {jsonl_file}: {status}\")\n",
    "\n",
    "        if status == \"completed\" and output_file_id:\n",
    "            try:\n",
    "                file_response = client.files.content(output_file_id)\n",
    "                results[jsonl_file] = file_response.text\n",
    "                print(f\"Results retrieved for {jsonl_file}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching results for {jsonl_file}: {e}\")\n",
    "        else:\n",
    "            print(f\"Batch {batch_id} is not completed or has no output file.\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Fetch batch results\n",
    "results = fetch_batch_results(client, batch_ids)\n",
    "print(\"Batch Results Retrieved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Answer Based on Category\n",
    "def extract_answer(response_text, category):\n",
    "    \"\"\"\n",
    "    Extracts the answer from response text based on the category prefix.\n",
    "\n",
    "    Args:\n",
    "        response_text (str): Full response text from GPT4o API.\n",
    "        category (str): Prompt category (e.g., \"eng_abbreviations\" or \"kor_abbreviations\").\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted answer or full response if no match is found.\n",
    "    \"\"\"\n",
    "    if category.startswith(\"eng_\"):\n",
    "        match = re.search(r\"Answer:\\s*(.*)\", response_text)\n",
    "    else:\n",
    "        match = re.search(r\"답변:\\s*(.*)\", response_text)\n",
    "\n",
    "    return match.group(1).strip() if match else response_text  # Extracted answer or full response\n",
    "\n",
    "# Map Custom ID to Original Input\n",
    "def map_custom_id_to_input(data):\n",
    "    \"\"\"\n",
    "    Creates a mapping from custom_id to the original transformed input word.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of input data containing \"transformed\" words.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping from custom_id to transformed input word.\n",
    "    \"\"\"\n",
    "    return {f\"request-{idx + 1}\": item[\"transformed\"] for idx, item in enumerate(data)}\n",
    "\n",
    "# Save Processed Results\n",
    "def save_results(results: dict, output_dir: str, data: list, category: str):\n",
    "    \"\"\"\n",
    "    Saves processed results into a JSON file.\n",
    "\n",
    "    Args:\n",
    "        results (list): List of dictionaries containing \"word\", \"response\", and \"answer\".\n",
    "        filename (str): Path to the output JSON file.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create mapping from custom_id to original input word\n",
    "    id_to_input_map = map_custom_id_to_input(data)\n",
    "\n",
    "    for jsonl_file, response_text in results.items():\n",
    "        lines = response_text.strip().split(\"\\n\")\n",
    "        response_data = [json.loads(line) for line in lines]\n",
    "        \n",
    "        processed_data = []\n",
    "        for entry in response_data:\n",
    "            custom_id = entry.get(\"custom_id\")  \n",
    "            response_content = entry[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"] if entry.get(\"response\") else \"\"\n",
    "\n",
    "            # Extract input word from mapping\n",
    "            prompt_prefix = custom_id.split(\"-request\")[0]  \n",
    "            clean_custom_id = custom_id.replace(f\"{prompt_prefix}-\", \"\")  \n",
    "            input_text = id_to_input_map.get(clean_custom_id, \"Unknown\")\n",
    "\n",
    "            # Extract answer using appropriate format\n",
    "            extracted_answer = extract_answer(response_content, category)\n",
    "\n",
    "            processed_data.append({\n",
    "                \"word\": input_text,  # Store original transformed word\n",
    "                \"response\": response_content,  # Store full response\n",
    "                \"answer\": extracted_answer  # Store extracted answer\n",
    "            })\n",
    "\n",
    "        # Save results as JSON\n",
    "        json_output_path = os.path.join(output_dir, f\"{os.path.basename(jsonl_file)}.json\")\n",
    "        with open(json_output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(processed_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"Results saved to {json_output_path}\")\n",
    "\n",
    "# Save results\n",
    "RESULTS_DIR = \"results\"\n",
    "save_results(results, RESULTS_DIR, data, CATEGORY)\n",
    "print(\"Results Saved Successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
