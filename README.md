# Text-Manipulation
Large language models (LLMs) are advancing in many areas, but the extent to which they understand transformed language expressions has not been fully explored. In digital environments, variant language expressions are constantly being created and proliferated without clear rules. Therefore, LLMs need to be able to identify and process informal expressions effectively. In this study, we constructed a dataset of English and Korean variant texts that are difficult for LLMs to process. The dataset consists of visual and pronunciation variant expressions, contextual language such as abbreviations, and segmented consonant and vowel combinations. We evaluated the performance of restoring variant language through prompt engineering and found that Korean performance was relatively lower than English for all models, with difficulties in certain types.
<img width="1456" alt="intro" src="https://github.com/user-attachments/assets/d2cc58b8-3275-45be-9d5a-1a0f8d95d7a7" />
