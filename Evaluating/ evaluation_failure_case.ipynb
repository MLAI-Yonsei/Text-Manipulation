{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"R5MhvYWgpMwM"},"outputs":[],"source":["import os\n","import json\n","import re\n","import pandas as pd\n","import numpy as np\n","from gensim import models\n","from Levenshtein import distance as levenshtein"]},{"cell_type":"markdown","metadata":{"id":"Nx44QkzmpMwN"},"source":["## Load Dataset & Utility functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FN_1GPlYpMwO"},"outputs":[],"source":["# Load Dataset Function\n","def load_json(filepath: str) -> list:\n","    \"\"\"Loads a JSON file and returns a list of dictionaries.\"\"\"\n","    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n","        return json.load(f)\n","\n","# Text Preprocessing Function\n","def clean_text(text: str, keep_pipe=False) -> str:\n","    \"\"\"Cleans input text while preserving selected characters for evaluation.\"\"\"\n","    if isinstance(text, str):\n","        if keep_pipe:\n","            # Uncomment the following line if you need to remove all special characters except '|'\n","            #text = re.sub(r'[^a-zA-Z0-9ㄱ-ㅎㅏ-ㅣ가-힣| ]', '', text)\n","            pass\n","        else:\n","            # Uncomment the following line if you need to remove all special characters\n","            #text = re.sub(r'[^a-zA-Z0-9ㄱ-ㅎㅏ-ㅣ가-힣 ]', '', text)\n","            pass\n","\n","        # Uncomment the following line if case normalization is required (for English text tasks)\n","        #text = text.lower()\n","\n","        # This step is always applied: Removes spaces from the text\n","        text = text.replace(\" \", \"\")\n","    return text\n","\n","# Define Vectorization & Similarity Functions\n","def get_sentence_vector(sentence: str, model) -> np.ndarray:\n","    \"\"\"Computes the sentence vector using a pre-trained FastText model.\"\"\"\n","    tokens = sentence.split()\n","    valid_tokens = [token for token in tokens if token in model.wv.key_to_index]\n","    return np.mean([model.wv[token] for token in valid_tokens], axis=0) if valid_tokens else np.zeros(model.vector_size)\n","\n","def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n","    \"\"\"Computes cosine similarity between two vectors.\"\"\"\n","    norm1, norm2 = np.linalg.norm(vec1), np.linalg.norm(vec2)\n","    return np.dot(vec1, vec2) / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else -1.0"]},{"cell_type":"markdown","metadata":{"id":"zxZZl8oCpMwP"},"source":["## Load Pre-trained FastText Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q17tcqVppMwP"},"outputs":[],"source":["# Determine FastText Model Based on File Name\n","DATA_ORIGINAL = \" \"\n","filename = os.path.basename(DATA_ORIGINAL)\n","\n","if filename.startswith(\"kor_\"):\n","    model_path = \"cc.ko.300.bin\"\n","elif filename.startswith(\"eng_\"):\n","    model_path = \"cc.en.300.bin\"\n","else:\n","    raise ValueError(\"Invalid file name! Must start with 'kor_' or 'eng_'.\")\n","\n","ko_model = models.fasttext.load_facebook_model(model_path)\n","print(f\"FastText model loaded: {model_path}\")"]},{"cell_type":"markdown","metadata":{"id":"JafRHoKhpMwQ"},"source":["## Evaluate All Models for Different Prompt Types"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y9YQ0s08pMwQ"},"outputs":[],"source":["# Define Evaluation Types\n","EVAL_TYPES = [\"zrs\", \"cot\", \"icl\"]\n","overall_results = {}\n","\n","# Load original dataset\n","data_original = load_json(DATA_ORIGINAL)\n","\n","# Iterate over each EVAL_TYPE and compute performance\n","for eval_type in EVAL_TYPES:\n","    print(f\"\\nEvaluating {eval_type.upper()}...\")\n","\n","    # Load dataset for the current eval_type\n","    gpt4o = load_json(f\"gpt4o_{eval_type}.json\")\n","    gemini = load_json(f\"gemini_{eval_type}.json\")\n","    claude = load_json(f\"claude_{eval_type}.json\")\n","    gpto3 = load_json(f\"{eval_type}.json\")\n","\n","    # Ensure minimum length for consistency\n","    min_length = min(len(data_original), len(gpt4o), len(gemini), len(claude), len(gpto3))\n","\n","    # Convert to DataFrame\n","    df = pd.DataFrame({\n","        \"original\": [item[\"original\"] for item in data_original[:min_length]],\n","        \"transformed\": [item[\"transformed\"] for item in data_original[:min_length]],\n","        \"gpt4o\": [item[\"Answer\"] for item in gpt4o[:min_length]],\n","        \"gemini\": [item[\"Answer\"] for item in gemini[:min_length]],\n","        \"claude\": [item[\"Answer\"] for item in claude[:min_length]],\n","        \"gpto3\": [item[\"Answer\"] for item in gpto3[:min_length]],\n","    })\n","\n","    # Apply Text Preprocessing\n","    df[\"original\"] = df[\"original\"].apply(lambda x: clean_text(x, keep_pipe=True))\n","    df[[\"transformed\", \"gpt4o\", \"gemini\", \"claude\", \"gpto3\"]] = \\\n","        df[[\"transformed\", \"gpt4o\", \"gemini\", \"claude\", \"gpto3\"]].applymap(lambda x: clean_text(x, keep_pipe=False))\n","\n","    # 텍스트 정제 적용\n","    df = df.fillna('')\n","\n","    # Model Evaluation\n","    eval_results = {}\n","\n","    for model in [\"gpt4o\", \"gemini\", \"claude\", \"gpto3\"]:\n","        df[f\"{model}_accuracy\"] = [\n","            100 if row[f\"{model}\"] in row[\"original\"].split(\"|\") else 0\n","            for _, row in df.iterrows()\n","        ]\n","        df[f\"{model}_edit_distance\"] = [\n","            min(levenshtein(row[f\"{model}\"], gt) for gt in row[\"original\"].split(\"|\"))\n","            for _, row in df.iterrows()\n","        ]\n","        df[f\"{model}_cosine_similarity\"] = [\n","            max(cosine_similarity(get_sentence_vector(row[f\"{model}\"], ko_model), get_sentence_vector(gt, ko_model))\n","                for gt in row[\"original\"].split(\"|\"))\n","            for _, row in df.iterrows()\n","        ]\n","\n","        # Store evaluation metrics\n","        eval_results[model.upper()] = {\n","            \"Accuracy\": np.mean(df[f\"{model}_accuracy\"]),\n","            \"Edit Distance\": np.mean(df[f\"{model}_edit_distance\"]),\n","            \"Cosine Similarity\": np.mean(df[f\"{model}_cosine_similarity\"])\n","        }\n","\n","    overall_results[eval_type.upper()] = eval_results\n","\n","print(\"\\nAll evaluations completed!\")\n"]},{"cell_type":"markdown","metadata":{"id":"kuEOTEF1pMwR"},"source":["## Compute Evaluation Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BWRKYomfpMwR"},"outputs":[],"source":["# Display Final Performance Results for All Evaluations\n","for eval_type, results in overall_results.items():\n","    df_performance = pd.DataFrame.from_dict(results, orient='index')\n","    df_performance.rename(columns={'Accuracy': 'Accuracy(%)', 'Edit Distance': 'Edit Distance', 'Cosine Similarity': 'Cosine Similarity'}, inplace=True)\n","\n","    print(f\"\\nPerformance for {eval_type.upper()}:\")\n","    print(df_performance)"]}],"metadata":{"kernelspec":{"display_name":"ds_study","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}